{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
   "id": "2a2aee13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV: C:\\Users\\j0sep\\Mat-Vis-Net-2\\data\\san_leandro_products.csv\n",
      "Embeddings: C:\\Users\\j0sep\\Mat-Vis-Net-2\\data\\image_embs.npy\n",
      "Images dir: C:\\Users\\j0sep\\Mat-Vis-Net-2\\images\n",
      "Full CSV rows: 1419\n",
      "Filtered rows with images (used for embeddings): 1419\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>name</th>\n",
       "      <th>category_slug</th>\n",
       "      <th>product_url</th>\n",
       "      <th>image_url</th>\n",
       "      <th>image_filename</th>\n",
       "      <th>row_id</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>pca_x</th>\n",
       "      <th>pca_y</th>\n",
       "      <th>surface_type</th>\n",
       "      <th>material_group</th>\n",
       "      <th>cluster_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100996982</td>\n",
       "      <td>Biscayne Blue Porcelain Tile</td>\n",
       "      <td>/tile</td>\n",
       "      <td>https://www.flooranddecor.com/porcelain-tile/b...</td>\n",
       "      <td>https://i8.amplience.net/i/flooranddecor/10099...</td>\n",
       "      <td>100996982.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100983915</td>\n",
       "      <td>Sedon Lodge Natural Wood Plank Porcelain Tile</td>\n",
       "      <td>/tile</td>\n",
       "      <td>https://www.flooranddecor.com/porcelain-tile/s...</td>\n",
       "      <td>https://i8.amplience.net/i/flooranddecor/10098...</td>\n",
       "      <td>100983915.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100294875</td>\n",
       "      <td>Navarro Beige Wood Plank Matte Porcelain Tile</td>\n",
       "      <td>/tile</td>\n",
       "      <td>https://www.flooranddecor.com/porcelain-tile/n...</td>\n",
       "      <td>https://i8.amplience.net/i/flooranddecor/10029...</td>\n",
       "      <td>100294875.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101068815</td>\n",
       "      <td>Honeycomb Waterproof Rigid Core Luxury Vinyl P...</td>\n",
       "      <td>/tile</td>\n",
       "      <td>https://www.flooranddecor.com/nucore-performan...</td>\n",
       "      <td>https://i8.amplience.net/i/flooranddecor/10106...</td>\n",
       "      <td>101068815.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100572429</td>\n",
       "      <td>Tauleto Bianco Matte Porcelain Tile</td>\n",
       "      <td>/tile</td>\n",
       "      <td>https://www.flooranddecor.com/porcelain-tile/t...</td>\n",
       "      <td>https://i8.amplience.net/i/flooranddecor/10057...</td>\n",
       "      <td>100572429.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sku                                               name category_slug  \\\n",
       "0  100996982                       Biscayne Blue Porcelain Tile         /tile   \n",
       "1  100983915      Sedon Lodge Natural Wood Plank Porcelain Tile         /tile   \n",
       "2  100294875      Navarro Beige Wood Plank Matte Porcelain Tile         /tile   \n",
       "3  101068815  Honeycomb Waterproof Rigid Core Luxury Vinyl P...         /tile   \n",
       "4  100572429                Tauleto Bianco Matte Porcelain Tile         /tile   \n",
       "\n",
       "                                         product_url  \\\n",
       "0  https://www.flooranddecor.com/porcelain-tile/b...   \n",
       "1  https://www.flooranddecor.com/porcelain-tile/s...   \n",
       "2  https://www.flooranddecor.com/porcelain-tile/n...   \n",
       "3  https://www.flooranddecor.com/nucore-performan...   \n",
       "4  https://www.flooranddecor.com/porcelain-tile/t...   \n",
       "\n",
       "                                           image_url image_filename  row_id  \\\n",
       "0  https://i8.amplience.net/i/flooranddecor/10099...  100996982.jpg     NaN   \n",
       "1  https://i8.amplience.net/i/flooranddecor/10098...  100983915.jpg     NaN   \n",
       "2  https://i8.amplience.net/i/flooranddecor/10029...  100294875.jpg     NaN   \n",
       "3  https://i8.amplience.net/i/flooranddecor/10106...  101068815.jpg     NaN   \n",
       "4  https://i8.amplience.net/i/flooranddecor/10057...  100572429.jpg     NaN   \n",
       "\n",
       "   cluster_id  pca_x  pca_y  surface_type  material_group  cluster_size  \n",
       "0         NaN    NaN    NaN           NaN             NaN           NaN  \n",
       "1         NaN    NaN    NaN           NaN             NaN           NaN  \n",
       "2         NaN    NaN    NaN           NaN             NaN           NaN  \n",
       "3         NaN    NaN    NaN           NaN             NaN           NaN  \n",
       "4         NaN    NaN    NaN           NaN             NaN           NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "id": "2a2aee13",
   "metadata": {},
   "outputs": [],
>>>>>>> upstream-src/main
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image  # just for loading images\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "CSV_PATH = PROJECT_ROOT / \"data\" / \"san_leandro_products.csv\"\n",
    "EMBS_PATH = PROJECT_ROOT / \"data\" / \"image_embs.npy\"\n",
    "IMAGES_DIR = PROJECT_ROOT / \"images\"  # <-- folder with your JPGs\n",
    "\n",
    "print(\"CSV:\", CSV_PATH)\n",
    "print(\"Embeddings:\", EMBS_PATH)\n",
    "print(\"Images dir:\", IMAGES_DIR)\n",
    "\n",
    "# Load full CSV (all products)\n",
    "raw_df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Filtered view: only products that have an image file\n",
    "IMAGE_COL = \"image_filename\"\n",
    "if IMAGE_COL not in raw_df.columns:\n",
    "    raise ValueError(f\"{IMAGE_COL!r} column not found in CSV\")\n",
    "\n",
    "df = raw_df[raw_df[IMAGE_COL].notna() & (raw_df[IMAGE_COL] != \"\")]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(\"Full CSV rows:\", len(raw_df))\n",
    "print(\"Filtered rows with images (used for embeddings):\", len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223e67f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# If you don't already have these installed in your venv, run:\n",
    "#   pip install \"torch\" \"transformers\"\n",
    "import torch\n",
    "from transformers import CLIPModel, CLIPProcessor\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "def build_clip_image_embs(df, images_dir, image_col=\"image_filename\", batch_size=32):\n",
    "    \"\"\"\n",
    "    Build CLIP image embeddings for every row in df and return:\n",
    "      - image_embs: numpy array of shape (N, D)\n",
    "      - df_aligned: df restricted to rows that actually have an image file\n",
    "    \"\"\"\n",
    "    model_name = \"openai/clip-vit-base-patch32\"\n",
    "    print(f\"Loading CLIP model: {model_name}\")\n",
    "    processor = CLIPProcessor.from_pretrained(model_name)\n",
    "    model = CLIPModel.from_pretrained(model_name).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_embs = []\n",
    "    keep_indices = []\n",
    "\n",
    "    n = len(df)\n",
    "    print(f\"Computing embeddings for {n} products...\")\n",
    "\n",
    "    for start in range(0, n, batch_size):\n",
    "        batch = df.iloc[start : start + batch_size]\n",
    "        images = []\n",
    "        batch_indices = []\n",
    "\n",
    "        for idx, row in batch.iterrows():\n",
    "            fname = str(row[image_col])\n",
    "            img_path = images_dir / fname\n",
    "            if not img_path.is_file():\n",
    "                print(f\"WARNING: image file missing for index {idx}: {img_path}\")\n",
    "                continue\n",
    "\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            images.append(img)\n",
    "            batch_indices.append(idx)\n",
    "\n",
    "        if not images:\n",
    "            continue\n",
    "\n",
    "        inputs = processor(images=images, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            emb = model.get_image_features(**inputs)\n",
    "\n",
    "        all_embs.append(emb.cpu().numpy())\n",
    "        keep_indices.extend(batch_indices)\n",
    "\n",
    "        print(f\"  processed {min(start + batch_size, n)}/{n} rows\", end=\"\\r\")\n",
    "\n",
    "    if not all_embs:\n",
    "        raise RuntimeError(\n",
    "            \"No embeddings were built. Check that your images directory is correct.\"\n",
    "        )\n",
    "\n",
    "    image_embs = np.vstack(all_embs)\n",
    "    df_aligned = df.loc[keep_indices].reset_index(drop=True)\n",
    "\n",
    "    print()\n",
    "    print(\"Embeddings built. image_embs shape:\", image_embs.shape)\n",
    "    print(\"Aligned df length:\", len(df_aligned))\n",
    "\n",
    "    return image_embs, df_aligned\n",
    "\n",
    "\n",
    "# --- Load or rebuild embeddings so that they ALWAYS match df ---\n",
    "\n",
    "if EMBS_PATH.exists():\n",
    "    image_embs = np.load(EMBS_PATH)\n",
    "    print(\"Loaded existing embeddings:\", image_embs.shape)\n",
    "else:\n",
    "    image_embs = None\n",
    "    print(\"No existing embeddings file found at\", EMBS_PATH)\n",
    "\n",
    "if (image_embs is None) or (image_embs.shape[0] != len(df)):\n",
    "    print(\"Embeddings are missing or out of sync with CSV -> rebuilding from images.\")\n",
    "    image_embs, df = build_clip_image_embs(df, IMAGES_DIR, IMAGE_COL, batch_size=32)\n",
    "    np.save(EMBS_PATH, image_embs)\n",
    "    print(\"Saved fresh embeddings to\", EMBS_PATH)\n",
    "\n",
    "print(\"Final check -> image_embs.shape[0]:\", image_embs.shape[0], \" len(df):\", len(df))\n",
    "\n",
    "if image_embs.shape[0] != len(df):\n",
    "    raise ValueError(\n",
    "        \"After rebuild, embeddings still do not align with df. \"\n",
    "        \"This would only happen if some rows were dropped while building embeddings \"\n",
    "        \"but df was not updated. Double-check your CSV and images.\"\n",
    "    )\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=20, metric=\"cosine\")\n",
    "nn.fit(image_embs)\n",
    "\n",
    "print(\"kNN index built over\", image_embs.shape[0], \"products\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f582f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- material bucketing + helpers ---\n",
    "\n",
    "def _compute_material_bucket(row) -> str:\n",
    "    \"\"\"\n",
    "    Coarse material/type bucket so we don't mix wood planks with vinyl, tile,\n",
    "    or installation trim (stair nose, etc.). Uses category_slug + name + URL.\n",
    "    \"\"\"\n",
    "    cat = str(row.get(\"category_slug\", \"\")).lower().strip()\n",
    "    base = cat.strip(\"/\").split(\"/\")[-1]  # e.g. \"engineered-hardwood-wood\"\n",
    "    name = str(row.get(\"name\", \"\")).lower()\n",
    "    url = str(row.get(\"product_url\", \"\")).lower()\n",
    "\n",
    "    # --- installation / trim first (never treated as surface) ---\n",
    "    if \"installation-materials\" in base:\n",
    "        return \"install\"\n",
    "    if any(k in name for k in [\"stair nose\", \"stairnose\", \"stair-nose\"]):\n",
    "        return \"trim\"\n",
    "    if \"moldings-wood\" in url or \"molding\" in name:\n",
    "        return \"trim\"\n",
    "\n",
    "    # --- main surface families (from category_slug) ---\n",
    "    if \"wood\" in base:\n",
    "        return \"wood\"\n",
    "    if \"laminate\" in base:\n",
    "        return \"laminate\"\n",
    "    if \"vinyl\" in base or \"nucore\" in base:\n",
    "        return \"vinyl\"\n",
    "    if \"tile\" in base:\n",
    "        return \"tile\"\n",
    "    if \"stone\" in base:\n",
    "        return \"stone\"\n",
    "    if \"decoratives\" in base:\n",
    "        return \"decoratives\"\n",
    "    if \"fixtures\" in base or \"bathroom-accessories\" in base:\n",
    "        return \"fixtures\"\n",
    "\n",
    "    return \"other\"\n",
    "\n",
    "\n",
    "# compute once for the DataFrame used by embeddings\n",
    "if \"material_bucket\" not in df.columns:\n",
    "    df[\"material_bucket\"] = df.apply(_compute_material_bucket, axis=1)\n",
    "\n",
    "\n",
    "def get_index_by_sku(query_sku: str) -> int:\n",
    "    \"\"\"\n",
    "    Return the row index in df corresponding to the given SKU.\n",
    "    Only SKUs present in the filtered df (with embeddings) are valid.\n",
    "    \"\"\"\n",
    "    sku_str = str(query_sku).strip()\n",
    "    matches = df.index[df[\"sku\"].astype(str).str.strip() == sku_str].tolist()\n",
    "    if not matches:\n",
    "        # Check if it's only in the raw CSV but not in the filtered df\n",
    "        exists_in_raw = raw_df[\"sku\"].astype(str).str.strip().eq(sku_str).any()\n",
    "        if exists_in_raw:\n",
    "            raise ValueError(\n",
    "                f\"SKU {sku_str!r} exists in san_leandro_products.csv but \"\n",
    "                \"does not have an embedding (likely missing image_filename \"\n",
    "                \"in the filtered set).\"\n",
    "            )\n",
    "        raise ValueError(f\"SKU {sku_str!r} not found in san_leandro_products.csv.\")\n",
    "    return matches[0]\n",
    "\n",
    "\n",
    "def find_index_by_name_substring(substr: str, occurrence: int = 0) -> int:\n",
    "    \"\"\"\n",
    "    Find the index of a product whose name contains the given substring\n",
    "    (case-insensitive). If multiple matches exist, `occurrence` chooses\n",
    "    which one (0 = first).\n",
    "    \"\"\"\n",
    "    mask = df[\"name\"].str.contains(substr, case=False, na=False)\n",
    "    matches = df[mask]\n",
    "    if matches.empty:\n",
    "        raise ValueError(f\"No products with name containing {substr!r}\")\n",
    "    if occurrence >= len(matches):\n",
    "        raise ValueError(\n",
    "            f\"Only {len(matches)} matches for {substr!r}, but occurrence={occurrence}\"\n",
    "        )\n",
    "    return matches.index[occurrence]\n",
    "\n",
    "\n",
    "def search_similar_by_index(query_idx: int, top_k: int = 10, exclude_same: bool = True):\n",
    "    \"\"\"\n",
    "    Given a row index in df, return the top_k most similar products by image\n",
    "    embedding, but RESTRICTED to the same material bucket.\n",
    "    \"\"\"\n",
    "    query_vec = image_embs[query_idx].reshape(1, -1)\n",
    "    # ask for extra neighbors in case many get filtered out by material bucket\n",
    "    distances, indices = nn.kneighbors(query_vec, n_neighbors=top_k + 30)\n",
    "\n",
    "    query_bucket = df.loc[query_idx, \"material_bucket\"]\n",
    "\n",
    "    dist_list = distances[0].tolist()\n",
    "    idx_list = indices[0].tolist()\n",
    "\n",
    "    results = []\n",
    "    for dist, idx in zip(dist_list, idx_list):\n",
    "        if exclude_same and idx == query_idx:\n",
    "            continue\n",
    "\n",
    "        row = df.iloc[idx]\n",
    "        if df.loc[idx, \"material_bucket\"] != query_bucket:\n",
    "            # different material/type -> skip\n",
    "            continue\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"index\": int(idx),\n",
    "                \"rank\": len(results) + 1,\n",
    "                \"sku\": row[\"sku\"],\n",
    "                \"name\": row[\"name\"],\n",
    "                \"category_slug\": row.get(\"category_slug\"),\n",
    "                \"material_bucket\": df.loc[idx, \"material_bucket\"],\n",
    "                \"distance\": float(dist),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if len(results) >= top_k:\n",
    "            break\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def show_product_image(row, title_prefix: str = \"\"):\n",
    "    \"\"\"\n",
    "    Display the product image for a given row of df.\n",
    "    \"\"\"\n",
    "    img_name = row.get(\"image_filename\")\n",
    "    if not isinstance(img_name, str) or not img_name:\n",
    "        print(\"No image_filename for this row.\")\n",
    "        return\n",
    "\n",
    "    img_path = IMAGES_DIR / img_name\n",
    "    if not img_path.exists():\n",
    "        print(\"Image file not found:\", img_path)\n",
    "        return\n",
    "\n",
    "    img = Image.open(img_path)\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    title = f\"{title_prefix}SKU {row['sku']} â€“ {row['name']}\"\n",
    "    plt.title(title, fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_results_with_images(query_idx: int, top_k: int = 10):\n",
    "    \"\"\"\n",
    "    Convenience: show query product + top_k similar products with images.\n",
    "    \"\"\"\n",
    "    query_row = df.iloc[query_idx]\n",
    "    query_bucket = df.loc[query_idx, \"material_bucket\"]\n",
    "\n",
    "    print(\"QUERY PRODUCT\")\n",
    "    print(\"SKU:\", query_row[\"sku\"])\n",
    "    print(\"Name:\", query_row[\"name\"])\n",
    "    print(\"Category:\", query_row.get(\"category_slug\"))\n",
    "    print(\"Material bucket:\", query_bucket)\n",
    "    show_product_image(query_row, title_prefix=\"QUERY: \")\n",
    "\n",
    "    results = search_similar_by_index(query_idx, top_k=top_k)\n",
    "\n",
    "    print(\"\\nSIMILAR PRODUCTS\")\n",
    "    print(\"--------------------------------------------\")\n",
    "    for r in results:\n",
    "        row = df.iloc[r[\"index\"]]\n",
    "        print(\n",
    "            f\"Rank {r['rank']} | SKU {r['sku']} | dist={r['distance']:.4f} \"\n",
    "            f\"| bucket={r['material_bucket']}\"\n",
    "        )\n",
    "        print(\"  Name:\", r[\"name\"])\n",
    "        print(\"  Category:\", r[\"category_slug\"])\n",
    "        show_product_image(row, title_prefix=f\"RANK {r['rank']}: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fb2ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_sku = \"101156321\"  # change this to a valid SKU from df[\"sku\"]\n",
    "\n",
    "query_idx = get_index_by_sku(query_sku)\n",
    "query_row = df.iloc[query_idx]\n",
    "\n",
    "print(\"QUERY PRODUCT\")\n",
    "print(\"SKU:\", query_row[\"sku\"])\n",
    "print(\"Name:\", query_row[\"name\"])\n",
    "print(\"Category:\", query_row.get(\"category_slug\"))\n",
    "print()\n",
    "\n",
    "results = search_similar_by_index(query_idx, top_k=5)\n",
    "\n",
    "print(\"SIMILAR PRODUCTS\")\n",
    "print(\"----------------\")\n",
    "for r in results:\n",
    "    print(f\"Rank {r['rank']} | SKU {r['sku']} | dist={r['distance']:.4f}\")\n",
    "    print(\"  Name:\", r[\"name\"])\n",
    "    print(\"  Category:\", r[\"category_slug\"])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216a28f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_sku = \"101156321\"  # change to a valid SKU from df[\"sku\"]\n",
    "\n",
    "query_idx = get_index_by_sku(query_sku)\n",
    "show_results_with_images(query_idx, top_k=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
